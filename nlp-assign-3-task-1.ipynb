{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6066255,"sourceType":"datasetVersion","datasetId":3471819},{"sourceId":13569013,"sourceType":"datasetVersion","datasetId":8619752},{"sourceId":13679746,"sourceType":"datasetVersion","datasetId":8699102}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip -q install -U transformers datasets evaluate accelerate scikit-learn seaborn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T22:10:43.752174Z","iopub.execute_input":"2025-11-10T22:10:43.752526Z","iopub.status.idle":"2025-11-10T22:10:48.397180Z","shell.execute_reply.started":"2025-11-10T22:10:43.752497Z","shell.execute_reply":"2025-11-10T22:10:48.396127Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"#Cell2Imports, GPU Check,Hyperparameters, Path\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nimport torch\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom datasets import Dataset\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    DataCollatorWithPadding,\n    Trainer,\n    TrainingArguments,\n)\n\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\nset_seed(42)\n\nprint(\"CUDA available:\", torch.cuda.is_available())\nif torch.cuda.is_available():\n    print(\"GPU:\", torch.cuda.get_device_name(0))\n\nCSV_PATH = \"/kaggle/input/sentiment/sentiment.csv\"   # Your explicit path\nMODEL_NAME = \"bert-base-uncased\"\nMAX_LENGTH = 256\nBATCH_SIZE = 16          # Drop to 8 if OOM\nEPOCHS = 3\nLEARNING_RATE = 2e-5\nWARMUP_RATIO = 0.06\nWEIGHT_DECAY = 0.01\nOUTPUT_DIR = \"/kaggle/working/sentiment_outputs\"\nos.makedirs(OUTPUT_DIR, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T22:11:01.119447Z","iopub.execute_input":"2025-11-10T22:11:01.120255Z","iopub.status.idle":"2025-11-10T22:11:30.253657Z","shell.execute_reply.started":"2025-11-10T22:11:01.120200Z","shell.execute_reply":"2025-11-10T22:11:30.252715Z"}},"outputs":[{"name":"stderr","text":"2025-11-10 22:11:13.418005: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1762812673.669327      39 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1762812673.736217      39 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"CUDA available: True\nGPU: Tesla T4\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"#cell3Load CSV, Normalize Column Names\ndf = pd.read_csv(CSV_PATH)\nprint(\"Original columns:\", list(df.columns))\n\n# Strip whitespace from headers (you said you already cleaned, but this is safe)\ndf.columns = df.columns.str.strip()\n\nprint(\"Columns after strip:\", list(df.columns))\nprint(df.head(3))\n\nassert \"Text\" in df.columns, \"Expected 'Text' column not found.\"\nassert \"Sentiment\" in df.columns, \"Expected 'Sentiment' column not found.\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T22:11:47.818483Z","iopub.execute_input":"2025-11-10T22:11:47.818776Z","iopub.status.idle":"2025-11-10T22:11:47.830079Z","shell.execute_reply.started":"2025-11-10T22:11:47.818755Z","shell.execute_reply":"2025-11-10T22:11:47.829389Z"}},"outputs":[{"name":"stdout","text":"Original columns: ['Text', 'Sentiment', ' Source', ' Date/Time', ' User ID', ' Location', ' Confidence Score']\nColumns after strip: ['Text', 'Sentiment', 'Source', 'Date/Time', 'User ID', 'Location', 'Confidence Score']\n                        Text  Sentiment         Source             Date/Time  \\\n0       I love this product!   Positive        Twitter   2023-06-15 09:23:14   \n1  The service was terrible.   Negative   Yelp Reviews   2023-06-15 11:45:32   \n2     This movie is amazing!   Positive           IMDb   2023-06-15 14:10:22   \n\n        User ID      Location  Confidence Score  \n0      @user123      New York              0.85  \n1       user456   Los Angeles              0.65  \n2   moviefan789        London              0.92  \n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"#cell4Clean Text & Normalize Sentiment Labels\ndef clean_text(s):\n    if not isinstance(s, str):\n        s = \"\" if pd.isna(s) else str(s)\n    s = s.strip()\n    s = \" \".join(s.split())\n    return s\n\ndef normalize_label(x):\n    if pd.isna(x):\n        return None\n    s = str(x).strip().lower()\n    if s in {\"negative\", \"neutral\", \"positive\"}:\n        return s\n    variants = {\n        \"negative\": {\"neg\", \"negatives\", \"bad\", \"-1\", \"0\"},\n        \"neutral\":  {\"neu\", \"neut\", \"ok\", \"1\"},\n        \"positive\": {\"pos\", \"positives\", \"good\", \"great\", \"2\"},\n    }\n    for canon, vs in variants.items():\n        if s in vs:\n            return canon\n    try:\n        v = int(float(s))\n        if v == 0: return \"negative\"\n        if v == 1: return \"neutral\"\n        if v == 2: return \"positive\"\n        if v == -1: return \"negative\"\n    except:\n        pass\n    return None\n\ndf[\"Text\"] = df[\"Text\"].astype(str).map(clean_text)\ndf[\"label_norm\"] = df[\"Sentiment\"].map(normalize_label)\n\nprint(\"Raw Sentiment counts:\")\nprint(df[\"Sentiment\"].value_counts(dropna=False))\nprint(\"\\nNormalized label counts:\")\nprint(df[\"label_norm\"].value_counts(dropna=False))\n\nbefore = len(df)\ndf = df[(df[\"Text\"].str.len() > 0) & (df[\"label_norm\"].notna())].copy()\nafter = len(df)\nprint(f\"\\nDropped {before - after} invalid rows. Final size: {after}\")\n\nlabel2id = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\nid2label = {v: k for k, v in label2id.items()}\ndf[\"label_id\"] = df[\"label_norm\"].map(label2id)\n\nprint(\"\\nFinal label distribution:\")\nprint(df[\"label_norm\"].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T22:11:51.693764Z","iopub.execute_input":"2025-11-10T22:11:51.694565Z","iopub.status.idle":"2025-11-10T22:11:51.719552Z","shell.execute_reply.started":"2025-11-10T22:11:51.694536Z","shell.execute_reply":"2025-11-10T22:11:51.718451Z"}},"outputs":[{"name":"stdout","text":"Raw Sentiment counts:\nSentiment\nPositive    53\nNegative    43\nName: count, dtype: int64\n\nNormalized label counts:\nlabel_norm\npositive    53\nnegative    43\nName: count, dtype: int64\n\nDropped 0 invalid rows. Final size: 96\n\nFinal label distribution:\nlabel_norm\npositive    53\nnegative    43\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"#Cell 5Stratified Split\ntrain_df, val_df = train_test_split(\n    df[[\"Text\", \"label_id\", \"label_norm\"]],\n    test_size=0.2,\n    random_state=42,\n    stratify=df[\"label_id\"]\n)\nprint(\"Train size:\", len(train_df), \"Validation size:\", len(val_df))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T22:12:04.137757Z","iopub.execute_input":"2025-11-10T22:12:04.138063Z","iopub.status.idle":"2025-11-10T22:12:04.152062Z","shell.execute_reply.started":"2025-11-10T22:12:04.138039Z","shell.execute_reply":"2025-11-10T22:12:04.151023Z"}},"outputs":[{"name":"stdout","text":"Train size: 76 Validation size: 20\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"#Cell 6Build HF Datasets & Tokenize\nfrom datasets import Dataset\n\ntrain_ds = Dataset.from_pandas(train_df.reset_index(drop=True))\nval_ds   = Dataset.from_pandas(val_df.reset_index(drop=True))\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n\ndef tokenize_fn(batch):\n    return tokenizer(batch[\"Text\"], truncation=True, padding=False, max_length=MAX_LENGTH)\n\ntrain_tok = train_ds.map(tokenize_fn, batched=True, remove_columns=train_ds.column_names)\nval_tok   = val_ds.map(tokenize_fn, batched=True, remove_columns=val_ds.column_names)\n\ntrain_tok = train_tok.add_column(\"labels\", train_df[\"label_id\"].tolist())\nval_tok   = val_tok.add_column(\"labels\", val_df[\"label_id\"].tolist())\n\ncollator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T22:12:07.448710Z","iopub.execute_input":"2025-11-10T22:12:07.449017Z","iopub.status.idle":"2025-11-10T22:12:08.545320Z","shell.execute_reply.started":"2025-11-10T22:12:07.448996Z","shell.execute_reply":"2025-11-10T22:12:08.544466Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab5b85e8650a4b17b80e17e8224283c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb85f28f231f4bd5a42234203c3ed9e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac7c69ae50344f84bcfb8c1def9fa87a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"677f9f90bca241548e76e25ec30905b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/76 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8db512fc9c9b43688828d253c3e888e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/20 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea1789ce4e5147dfb1d08f1980adb813"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"#Cell 7 â€“ Metrics Function\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, f1_score\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = np.argmax(logits, axis=-1)\n    acc = accuracy_score(labels, preds)\n    f1_macro = f1_score(labels, preds, average=\"macro\")\n    f1_weighted = f1_score(labels, preds, average=\"weighted\")\n    return {\"accuracy\": acc, \"f1_macro\": f1_macro, \"f1_weighted\": f1_weighted}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T22:12:15.158065Z","iopub.execute_input":"2025-11-10T22:12:15.158422Z","iopub.status.idle":"2025-11-10T22:12:15.163502Z","shell.execute_reply.started":"2025-11-10T22:12:15.158399Z","shell.execute_reply":"2025-11-10T22:12:15.162680Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"#cell8Load Model & TrainingArgument\nfrom transformers import (\n    AutoModelForSequenceClassification,\n    Trainer,\n    TrainingArguments,\n    EarlyStoppingCallback\n)\nimport os, torch, math\n\n# (Re)load model (if you retrain after changes)\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    MODEL_NAME,\n    num_labels=3,\n    id2label=id2label,\n    label2id=label2id,\n)\n\n# Derive warmup steps explicitly (optional clarity):\n# If warmup_ratio is supported, you can keep it. Below we compute steps for logging.\nsteps_per_epoch = math.ceil(len(train_tok) / BATCH_SIZE)\ntotal_train_steps = steps_per_epoch * EPOCHS\nwarmup_steps = int(total_train_steps * WARMUP_RATIO)\nprint(f\"Estimated steps/epoch: {steps_per_epoch}, total steps: {total_train_steps}, warmup steps: {warmup_steps}\")\n\n# Training arguments (using eval_strategy because your environment accepted that)\nargs = TrainingArguments(\n    output_dir=os.path.join(OUTPUT_DIR, \"checkpoints\"),\n    eval_strategy=\"epoch\",                # or 'evaluation_strategy' if needed\n    save_strategy=\"epoch\",\n    save_total_limit=2,                   # keep last 2 checkpoints\n    load_best_model_at_end=True,\n    metric_for_best_model=\"f1_macro\",\n    greater_is_better=True,\n    learning_rate=LEARNING_RATE,\n    per_device_train_batch_size=BATCH_SIZE,\n    per_device_eval_batch_size=BATCH_SIZE,\n    num_train_epochs=EPOCHS,\n    weight_decay=WEIGHT_DECAY,\n    warmup_ratio=WARMUP_RATIO,            # keep ratio; you logged warmup_steps above for clarity\n    logging_steps=1,                      # log every step (small dataset)\n    fp16=torch.cuda.is_available(),\n    report_to=\"none\",\n    seed=42,\n    data_seed=42,                         # reproducible shuffling if supported\n    save_safetensors=True,                # safer model files\n    # Uncomment if supported & desired:\n    # gradient_checkpointing=True,\n    # full_determinism=True,\n    # tf32=True,                          # if on Ampere+ GPU; safe performance boost\n)\n\n# Early stopping (optional)\ncallbacks = [EarlyStoppingCallback(early_stopping_patience=2, early_stopping_threshold=0.0001)]\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=train_tok,\n    eval_dataset=val_tok,\n    tokenizer=tokenizer,            # Future versions prefer 'processing_class'; fine for now\n    data_collator=collator,\n    compute_metrics=compute_metrics,\n    callbacks=callbacks\n)\n\ntrain_result = trainer.train()\nprint(\"Train metrics:\", train_result.metrics)\n\neval_result = trainer.evaluate()\nprint(\"Eval metrics:\", eval_result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T22:12:58.927799Z","iopub.execute_input":"2025-11-10T22:12:58.928479Z","iopub.status.idle":"2025-11-10T22:13:09.981723Z","shell.execute_reply.started":"2025-11-10T22:12:58.928456Z","shell.execute_reply":"2025-11-10T22:13:09.980625Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/tmp/ipykernel_39/1764962655.py:55: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"name":"stdout","text":"Estimated steps/epoch: 5, total steps: 15, warmup steps: 0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [9/9 00:09, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1 Macro</th>\n      <th>F1 Weighted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.938100</td>\n      <td>0.878169</td>\n      <td>0.850000</td>\n      <td>0.849624</td>\n      <td>0.848872</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.883000</td>\n      <td>0.725148</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.731500</td>\n      <td>0.670562</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train metrics: {'train_runtime': 10.026, 'train_samples_per_second': 22.741, 'train_steps_per_second': 0.898, 'total_flos': 2680467943104.0, 'train_loss': 0.9124410483572218, 'epoch': 3.0}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Eval metrics: {'eval_loss': 0.7251484990119934, 'eval_accuracy': 1.0, 'eval_f1_macro': 1.0, 'eval_f1_weighted': 1.0, 'eval_runtime': 0.0783, 'eval_samples_per_second': 255.441, 'eval_steps_per_second': 12.772, 'epoch': 3.0}\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"#cell9Confusion Matrix & Classification Report\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# Get predictions on validation set\npred = trainer.predict(val_tok)\ny_true = pred.label_ids\ny_pred = pred.predictions.argmax(-1)\n\n# Define the full class set and names\nlabels_all = [0, 1, 2]\ntarget_names_all = [id2label[i] for i in labels_all]\n\n# Confusion matrix using all labels (will show zero row/col for missing classes)\ncm = confusion_matrix(y_true, y_pred, labels=labels_all)\nprint(\"Confusion matrix (rows=true, cols=pred):\\n\", cm)\n\n# Classification report for all 3 classes; missing classes get zero support\nprint(\"\\nClassification report (all classes; zero_division=0):\\n\")\nprint(classification_report(\n    y_true,\n    y_pred,\n    labels=labels_all,\n    target_names=target_names_all,\n    zero_division=0,\n    digits=4\n))\n\n# Also show which classes actually appeared in y_true/y_pred\npresent = sorted(list(set(y_true.tolist()) | set(y_pred.tolist())))\nprint(\"Classes present in this validation set:\", [id2label[i] for i in present])\n\n# Pretty plot\nplt.figure(figsize=(4,3))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n            xticklabels=target_names_all,\n            yticklabels=target_names_all)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.title(\"Confusion Matrix\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T22:13:23.741645Z","iopub.execute_input":"2025-11-10T22:13:23.742456Z","iopub.status.idle":"2025-11-10T22:13:24.124360Z","shell.execute_reply.started":"2025-11-10T22:13:23.742430Z","shell.execute_reply":"2025-11-10T22:13:24.123641Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Confusion matrix (rows=true, cols=pred):\n [[ 9  0  0]\n [ 0  0  0]\n [ 0  0 11]]\n\nClassification report (all classes; zero_division=0):\n\n              precision    recall  f1-score   support\n\n    negative     1.0000    1.0000    1.0000         9\n     neutral     0.0000    0.0000    0.0000         0\n    positive     1.0000    1.0000    1.0000        11\n\n    accuracy                         1.0000        20\n   macro avg     0.6667    0.6667    0.6667        20\nweighted avg     1.0000    1.0000    1.0000        20\n\nClasses present in this validation set: ['negative', 'positive']\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 400x300 with 2 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAXoAAAEiCAYAAAD3fRkKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+yUlEQVR4nO3de1xM+f8H8Nd0m+5TuiiWyq2tXJLLqqxcInIJ6x7K3W6rSJZ2N6lFy66I/a7YC2ldv4tYrFuukbCp3DYhsrZQSrqoTOf3R7/ma1ScqZnOmen93Md5PMznnDnnPR/2PZ/5nM/5fAQMwzAghBCistS4DoAQQohiUaInhBAVR4meEEJUHCV6QghRcZToCSFExVGiJ4QQFUeJnhBCVBwlekIIUXGU6AkhRMVRoidylZGRgUGDBkEkEkEgECAuLk6u53/w4AEEAgG2bt0q1/Mqs759+6Jv375ch0F4jBK9Crp37x7mzJmDNm3aQFtbG4aGhnB1dUVUVBRKS0sVem0fHx9cv34dK1asQGxsLLp3767Q6zUmX19fCAQCGBoa1lqPGRkZEAgEEAgE+P7772U+/7///otly5YhJSVFDtES8j8aXAdA5Ovw4cMYO3YshEIhpk6dio4dO6K8vBwJCQlYtGgRbt68ic2bNyvk2qWlpUhMTMRXX32Fzz//XCHXsLKyQmlpKTQ1NRVy/vfR0NBASUkJ/vjjD4wbN05q3/bt26GtrY1Xr17V69z//vsvwsLCYG1tDUdHR9bvO378eL2uR5oOSvQqJDMzExMmTICVlRVOnToFS0tLyT4/Pz/cvXsXhw8fVtj1nz17BgAwMjJS2DUEAgG0tbUVdv73EQqFcHV1xc6dO2sk+h07dmDo0KHYu3dvo8RSUlICXV1daGlpNcr1iBJjiMqYO3cuA4C5cOECq+MrKiqY8PBwpk2bNoyWlhZjZWXFBAcHM69evZI6zsrKihk6dChz/vx5pkePHoxQKGRsbGyYmJgYyTGhoaEMAKnNysqKYRiG8fHxkfz5TdXvedPx48cZV1dXRiQSMXp6ekyHDh2Y4OBgyf7MzEwGALNlyxap98XHxzO9e/dmdHV1GZFIxIwYMYK5detWrdfLyMhgfHx8GJFIxBgaGjK+vr5McXHxe+vLx8eH0dPTY7Zu3coIhUImPz9fsu/y5csMAGbv3r0MAOa7776T7MvLy2MWLlzIdOzYkdHT02MMDAyYwYMHMykpKZJjTp8+XaP+3vycbm5ujIODA3P16lXm448/ZnR0dJiAgADJPjc3N8m5pk6dygiFwhqff9CgQYyRkRHz+PHj935Wolqoj16F/PHHH2jTpg1cXFxYHT9z5kwsXboUTk5OWLt2Ldzc3BAREYEJEybUOPbu3bsYM2YMBg4ciDVr1sDY2Bi+vr64efMmAGD06NFYu3YtAGDixImIjY3FunXrZIr/5s2bGDZsGMrKyhAeHo41a9ZgxIgRuHDhwjvfd/LkSXh4eODp06dYtmwZAgMDcfHiRbi6uuLBgwc1jh83bhxevnyJiIgIjBs3Dlu3bkVYWBjrOEePHg2BQIB9+/ZJynbs2IEPP/wQTk5ONY6/f/8+4uLiMGzYMERGRmLRokW4fv063Nzc8O+//wIA7OzsEB4eDgCYPXs2YmNjERsbiz59+kjOk5eXhyFDhsDR0RHr1q1Dv379ao0vKioKZmZm8PHxgVgsBgBs2rQJx48fx4YNG9CiRQvWn5WoCK6/aYh8vHjxggHAeHl5sTo+JSWFAcDMnDlTqjwoKIgBwJw6dUpSZmVlxQBgzp07Jyl7+vQpIxQKmYULF0rKqlvbb7ZmGYZ9i37t2rUMAObZs2d1xl1bi97R0ZExNzdn8vLyJGWpqamMmpoaM3Xq1BrXmz59utQ5R40axZiYmNR5zTc/h56eHsMwDDNmzBhmwIABDMMwjFgsZiwsLJiwsLBa6+DVq1eMWCyu8TmEQiETHh4uKbty5Uqtv1YYpqrVDoCJjo6udd+bLXqGYZhjx44xAJjly5cz9+/fZ/T19ZmRI0e+9zMS1UQtehVRWFgIADAwMGB1/JEjRwAAgYGBUuULFy4EgBp9+fb29vj4448lr83MzGBra4v79+/XO+a3VfftHzhwAJWVlazek52djZSUFPj6+qJZs2aS8s6dO2PgwIGSz/mmuXPnSr3++OOPkZeXJ6lDNiZNmoQzZ84gJycHp06dQk5ODiZNmlTrsUKhEGpqVf+ricVi5OXlQV9fH7a2tkhOTmZ9TaFQiGnTprE6dtCgQZgzZw7Cw8MxevRoaGtrY9OmTayvRVQLJXoVYWhoCAB4+fIlq+MfPnwINTU1tGvXTqrcwsICRkZGePjwoVR569ata5zD2NgY+fn59Yy4pvHjx8PV1RUzZ85E8+bNMWHCBOzZs+edSb86Tltb2xr77OzskJubi+LiYqnytz+LsbExAMj0WTw9PWFgYIDdu3dj+/bt6NGjR426rFZZWYm1a9eiffv2EAqFMDU1hZmZGdLS0vDixQvW12zZsqVMN16///57NGvWDCkpKVi/fj3Mzc1Zv5eoFkr0KsLQ0BAtWrTAjRs3ZHqfQCBgdZy6unqt5QyLlSjrukZ1/3E1HR0dnDt3DidPnsSUKVOQlpaG8ePHY+DAgTWObYiGfJZqQqEQo0ePRkxMDPbv319nax4AVq5cicDAQPTp0we//fYbjh07hhMnTsDBwYH1Lxegqn5kce3aNTx9+hQAcP36dZneS1QLJXoVMmzYMNy7dw+JiYnvPdbKygqVlZXIyMiQKn/y5AkKCgpgZWUlt7iMjY1RUFBQo/ztXw0AoKamhgEDBiAyMhK3bt3CihUrcOrUKZw+fbrWc1fHmZ6eXmPf33//DVNTU+jp6TXsA9Rh0qRJuHbtGl6+fFnrDexqv//+O/r164dffvkFEyZMwKBBg+Du7l6jTth+6bJRXFyMadOmwd7eHrNnz8bq1atx5coVuZ2fKBdK9Crkiy++gJ6eHmbOnIknT57U2H/v3j1ERUUBqOp6AFBjZExkZCQAYOjQoXKLq23btnjx4gXS0tIkZdnZ2di/f7/Ucc+fP6/x3uoHh8rKymo9t6WlJRwdHRETEyOVOG/cuIHjx49LPqci9OvXD9988w1++OEHWFhY1Hmcurp6jV8L//3vf/H48WOpsuovpNq+FGW1ePFiZGVlISYmBpGRkbC2toaPj0+d9UhUGz0wpULatm2LHTt2YPz48bCzs5N6MvbixYv473//C19fXwBAly5d4OPjg82bN6OgoABubm64fPkyYmJiMHLkyDqH7tXHhAkTsHjxYowaNQr+/v4oKSnBxo0b0aFDB6mbkeHh4Th37hyGDh0KKysrPH36FD/++CM++OAD9O7du87zf/fddxgyZAicnZ0xY8YMlJaWYsOGDRCJRFi2bJncPsfb1NTU8PXXX7/3uGHDhiE8PBzTpk2Di4sLrl+/ju3bt6NNmzZSx7Vt2xZGRkaIjo6GgYEB9PT08NFHH8HGxkamuE6dOoUff/wRoaGhkuGeW7ZsQd++fRESEoLVq1fLdD6iAjge9UMU4M6dO8ysWbMYa2trRktLizEwMGBcXV2ZDRs2SD0MVVFRwYSFhTE2NjaMpqYm06pVq3c+MPW2t4f11TW8kmGqHoTq2LEjo6Wlxdja2jK//fZbjeGV8fHxjJeXF9OiRQtGS0uLadGiBTNx4kTmzp07Na7x9hDEkydPMq6uroyOjg5jaGjIDB8+vM4Hpt4evrllyxYGAJOZmVlnnTKM9PDKutQ1vHLhwoWMpaUlo6Ojw7i6ujKJiYm1Dos8cOAAY29vz2hoaNT6wFRt3jxPYWEhY2VlxTg5OTEVFRVSxy1YsIBRU1NjEhMT3/kZiOoRMIwMd6AIIYQoHeqjJ4QQFUeJnhBCVBwlekIIUXGU6AkhRMVRoieEEBVHiZ4QQlQcJXpCCFFxKvlkrKnvLq5DUFn//Fz3nC6E8Jl2A7OdTld26yCXXvuhYRdSAJVM9IQQIncC5e0AoURPCCFsyHF20cZGiZ4QQtigFj0hhKg4tdoXrFEGlOgJIYQN6rohhBAVp8RdN7yKvLy8HOnp6Xj9+jXXoRBCiDSBgN3GQ7xI9CUlJZgxYwZ0dXXh4OCArKwsAMC8efPw7bffchwdIYSgqo+ezcZDvEj0wcHBSE1NxZkzZ6CtrS0pd3d3x+7duzmMjBBC/p9Ajd3GQ7zoo4+Li8Pu3bvRq1cvCN746ePg4IB79+5xGBkhhPw/nnbLsMGLRP/s2TOYm5vXKC8uLpZK/IQQwhmettbZ4EXk3bt3x+HDhyWvq5P7zz//DGdnZ67CIoSQ/1FXZ7fxEC9a9CtXrsSQIUNw69YtvH79GlFRUbh16xYuXryIs2fPch0eIYRQi76hevfujZSUFLx+/RqdOnXC8ePHYW5ujsTERHTr1o3r8AghRCHDK8+dO4fhw4ejRYsWEAgEiIuLk9rPMAyWLl0KS0tL6OjowN3dHRkZGTKHzosWPQC0bdsWP/30E9dhEEJI7RTQoi8uLkaXLl0wffp0jB49usb+1atXY/369YiJiYGNjQ1CQkLg4eGBW7duSY1QfB9eJHp3d3dMnjwZo0ePhqGhIdfhEEJITQoYIz9kyBAMGTKk1n0Mw2DdunX4+uuv4eXlBQDYtm0bmjdvjri4OEyYwH5tCF503Tg4OCA4OBgWFhYYO3YsDhw4gIqKCq7DIoSQ/2nkJ2MzMzORk5MDd3d3SZlIJMJHH32ExMREmc7Fi0QfFRWFx48fIy4uDnp6epg6dSqaN2+O2bNn081YQgg/sHxgqqysDIWFhVJbWVmZzJfLyckBADRv3lyqvHnz5pJ9bPEi0QOAmpoaBg0ahK1bt+LJkyfYtGkTLl++jP79+3MdGiGEsJ4CISIiAiKRSGqLiIjgNHRe9NG/KScnB7t27cJvv/2GtLQ09OzZk+uQCCGEdbdMcHAwAgMDpcqEQqHMl7OwsAAAPHnyBJaWlpLyJ0+ewNHRUaZz8aJFX1hYiC1btmDgwIFo1aoVNm7ciBEjRiAjIwOXLl3iOjxCCGHddSMUCmFoaCi11SfR29jYwMLCAvHx8ZKywsJCJCUlyfwgKS9a9M2bN4exsTHGjx+PiIgIdO/eneuQCCFEmgKGVxYVFeHu3buS15mZmUhJSUGzZs3QunVrzJ8/H8uXL0f79u0lwytbtGiBkSNHynQdXiT6gwcPYsCAAVBT48UPDEIIqUkBwyuvXr2Kfv36SV5Xd/n4+Phg69at+OKLL1BcXIzZs2ejoKAAvXv3xtGjR2UaQw8AAoZhGLlGzgOmvru4DkFl/fMz+7G7hPCJdgObtTojN7M6rjRudsMupACcteidnJwQHx8PY2NjdO3a9Z2zVCYnJzdiZIQQUgslnuuGs0Tv5eUluUHh5eVF0xETQvhNiXMUZ4k+NDRU8udly5ZxFQYhhLCizPcQeRF5mzZtkJeXV6O8oKAAbdq04SAixdPX1sDySV1x7fvheLR5DI585Y6uNs24Dktl7NqxHUMG9kePrp3gPWEsrqelcR2SSmmS9StgufEQLxL9gwcPIBaLa5SXlZXhn3/+4SAixVs3rSf6Oljgs82X0OfrozhzMwd7F/WFhZEO16EpvaN/HsH3qyMw5zM/7PrvftjafohP58yotTFBZNdU61cgELDa+IjT4ZUHDx6U/PnYsWMQiUSS12KxGPHx8bCxseEiNIXS1lTHsO4fYMr680i88wwAsDruBjwcW2Ba/3aI2Hed4wiVW2zMFoweMw4jR30CAPg6NAznzp1B3L69mDGLfyMilE1TrV++JnE2OE301YP+BQIBfHx8pPZpamrC2toaa9as4SAyxdJQF0BDXQ2vyiulykvLxejVwYyjqFRDRXk5bt+6iRmz5kjK1NTU0KuXC9JSr3EYmWpoyvWrzH30nCb6ysqqRGdjY4MrV67A1NSUy3AaTdGr17ickYsgLwdkZL/A0xdl+KRXa/RoZ4LMJ0Vch6fU8gvyIRaLYWJiIlVuYmKCzMz7HEWlOpp0/Spvg54fT8ZmZmbW+71lZWU1pgBlxBUQqGs2NCyF+mzzJayf0RM31o3Ea3El0h7mY9+lLHSxNuY6NEJILajrRg6Ki4tx9uxZZGVloby8XGqfv79/ne+LiIhAWFiYVJlOl0+g6zhGIXHKy4NnRRjx7SnoaqnDQEcTT168ws+fuuDhs2KuQ1NqxkbGUFdXr3FjMC8vr8n8YlSkply/lOgb6Nq1a/D09ERJSQmKi4vRrFkz5ObmQldXF+bm5u9M9LVNCWrjd0DRIctNSbkYJeViiHQ10a+TBcJ2p3IdklLT1NKCnb0Dki4lov+AqpV5KisrkZSUiAkTJ3McnfJryvVLffQNtGDBAgwfPhzR0dEQiUS4dOkSNDU1MXnyZAQEBLzzvUKhsMYUoHzvtgGAfh0tIBAAd7Nfwqa5PpaNd0RGdiF2JKh4P2cjmOIzDSFfLoaDQ0d07NQZv8XGoLS0FCNH1Vx8mciuydav8jbo+ZHoU1JSsGnTJqipqUFdXR1lZWVo06YNVq9eDR8fn1pXR1d2hjqa+HpsF7Qw1kFBcTn+uPoIK/Zex2uxys0x1+gGD/FE/vPn+PGH9cjNfQbbD+3w46afYaLiXQuNpanWL3XdNJCmpqbkZ5G5uTmysrJgZ2cHkUiER48ecRydYhy48ggHrqjmZ+ODid6TMdFbtbsSuNQU65cSfQN17doVV65cQfv27eHm5oalS5ciNzcXsbGx6NixI9fhEUIIBGrKm+h5cXdh5cqVkjURV6xYAWNjY3z66ad49uwZNm9mNwc0IYQoEk2B0EBvLh1obm6Oo0ePchgNIYTUxNckzgYvEj0hhPAdJfoGqmuFKYFAAG1tbbRr1w6+vr5SaysSQkhjoj76Bho8eDDu378PPT099OvXD/369YO+vj7u3buHHj16IDs7G+7u7jhwQHkehCKEqBbqo2+g3NxcLFy4ECEhIVLly5cvx8OHD3H8+HGEhobim2++gZeXF0dREkKaMr4mcTZ40aLfs2cPJk6cWKN8woQJ2LNnDwBg4sSJSE9Pb+zQCCEEgHK36HmR6LW1tXHx4sUa5RcvXoS2tjaAqvk0qv9MCCGNTaAmYLXxES+6bubNm4e5c+fir7/+Qo8ePQAAV65cwc8//4wvv/wSQNUKVI6OjhxGSQhpyvjaWmdDwDAMLyZX2b59O3744QdJ94ytrS3mzZuHSZMmAQBKS0slo3Dex9R3l0Jjbcr++XkC1yEQUi/aDWzWWgccYnXcg6hhDbuQAvCiRQ8A3t7e8Pb2rnO/jg4tmk0I4Y4yt+h50UcPAAUFBZKumufPnwMAkpOT8fjxY44jI4QQ5e6j50WiT0tLQ4cOHbBq1Sp89913KCgoAADs27cPwcHB3AZHCCFQzKgbsViMkJAQ2NjYQEdHB23btsU333wDefeo8yLRBwYGwtfXFxkZGVJ98J6enjh37hyHkRFCSBWBgN0mi1WrVmHjxo344YcfcPv2baxatQqrV6/Ghg0b5Bo7L/ror1y5gk2bNtUob9myJXJycjiIiBBCpCmij/7ixYvw8vLC0KFDAQDW1tbYuXMnLl++LNfr8KJFLxQKUVhYWKP8zp07MDMz4yAiQgiRpqYmYLWVlZWhsLBQaisrK6v1nC4uLoiPj8edO3cAAKmpqUhISMCQIUPkG7tcz1ZPI0aMQHh4OCoqKgBUfXNmZWVh8eLF+OSTTziOjhBC2HfdREREQCQSSW0RERG1nnPJkiWYMGECPvzwQ2hqaqJr166YP3/+O0cg1gcvum7WrFmDMWPGwNzcHKWlpXBzc0NOTg569eqFFStWcB0eIYRAjeWImuDgYAQGBkqVCYXCWo/ds2cPtm/fjh07dsDBwQEpKSmYP38+WrRoAR8fnwbHXI0XiV4kEuHEiRO4cOECUlNTUVRUBCcnJ7i7u3MdGiGEAGB/o1UoFNaZ2N+2aNEiSaseADp16oSHDx8iIiJC9RI9AMTHxyM+Ph5Pnz5FZWUl/v77b+zYsQMA8Ouvv3IcHSGkqWPbopdFSUkJ1NSke9DV1dVRWVkp1+vwItGHhYUhPDwc3bt3h6WlpVI/gUYIUU2KyEvDhw/HihUr0Lp1azg4OODatWuIjIzE9OnT5XodXiT66OhobN26FVOmTOE6FEIIqZUiEv2GDRsQEhKCzz77DE+fPkWLFi0wZ84cLF26VK7X4UWiLy8vh4uLC9dhEEJInRTR0WBgYIB169Zh3bp18j/5G3gxvHLmzJmS/nhCCOEjtuPo+YgXLfpXr15h8+bNOHnyJDp37gxNTU2p/ZGRkRxFRgghVZT53iEvEn1aWppkUZEbN25I7VPmyiWEqA5lTkW8SPSnT5/mOgRCCHknZW508iLRE0II3/G1/50NlUz0tNwdIUTelLhBr5qJnhBC5I26bgghRMUpcZ6nRE8IIWxQHz0hhKg46rohhBAVR4meEEJUnBLneUr0hBDCBvXRE0KIiqOuG0IIUXFKnOcp0RNCCBtqSpzpKdETQggL1EdPCCEqTonzPHeJfv369ayP9ff3V2AkhBDyfnQzth7Wrl3L6jiBQECJnhDCOSXO89wl+szMTK4uTQghMlNX4kxPffSEEMICdd3IwT///IODBw8iKysL5eXlUvtocXBCCNeUOM/zI9HHx8djxIgRaNOmDf7++2907NgRDx48AMMwcHJy4jo8QghR6nH0alwHAADBwcEICgrC9evXoa2tjb179+LRo0dwc3PD2LFjuQ6PEEKgpiZgtfERLxL97du3MXXqVACAhoYGSktLoa+vj/DwcKxatYrj6AghpKrrhs3GR/VK9OfPn8fkyZPh7OyMx48fAwBiY2ORkJBQryD09PQk/fKWlpa4d++eZF9ubm69zkkIIfKkJhCw2mT1+PFjTJ48GSYmJtDR0UGnTp1w9epV+cYu6xv27t0LDw8P6Ojo4Nq1aygrKwMAvHjxAitXrqxXEL169ZJ8SXh6emLhwoVYsWIFpk+fjl69etXrnIQQIk8Clpss8vPz4erqCk1NTfz555+4desW1qxZA2NjY3mGDgHDMIwsb+jatSsWLFiAqVOnwsDAAKmpqWjTpg2uXbuGIUOGICcnR+Yg7t+/j6KiInTu3BnFxcVYuHAhLl68iPbt2yMyMhJWVlYyne/Va5lDIISoOO0GDj3xjk1hddz2KY6sz7lkyRJcuHAB58+fr19QLMn80dPT09GnT58a5SKRCAUFBTIHIBaL8c8//6Bz584AqrpxoqOjZT4PIYQoEttx9GVlZZKejmpCoRBCobDGsQcPHoSHhwfGjh2Ls2fPomXLlvjss88wa9YsucRcTeauGwsLC9y9e7dGeUJCAtq0aSNzAOrq6hg0aBDy8/Nlfi8hhDQWtjdjIyIiIBKJpLaIiIhaz3n//n1s3LgR7du3x7Fjx/Dpp5/C398fMTExco1d5hb9rFmzEBAQgF9//RUCgQD//vsvEhMTERQUhJCQkHoF0bFjR9y/fx82Njb1ej8hhCga2xZ9cHAwAgMDpcpqa80DQGVlJbp37y65v9m1a1fcuHED0dHR8PHxaVjAb5A50S9ZsgSVlZUYMGAASkpK0KdPHwiFQgQFBWHevHn1CmL58uUICgrCN998g27dukFPT09qv6GhYb3OSwgh8qLOcox8Xd00tbG0tIS9vb1UmZ2dHfbu3StzfO8ic6IXCAT46quvsGjRIty9exdFRUWwt7eHvr5+vYPw9PQEAIwYMULqW5NhGAgEAojF4nqfmxBC5EERQ+RdXV2Rnp4uVXbnzh2ZB6C8T73vQ2tpadX4Jqqv06dPy+U8ymbXju2I2fILcnOfoYPth1jyZQg6/f9NadIwVLeK1RTrVxFTICxYsAAuLi5YuXIlxo0bh8uXL2Pz5s3YvHmzXK8j8/DKfv36vbOv6tSpUzIHkZWVhVatWtU4L8MwePToEVq3bi3T+ZRheOXRP4/g6+Av8HVoGDp16oLtsTE4fvwoDhw6ChMTE67DU2pUt4qlrPXb0OGVs/bcYHXcT+M6ynTeQ4cOITg4GBkZGbCxsUFgYKDcR93InOgXLFgg9bqiogIpKSm4ceMGfHx8EBUVJXMQ6urqyM7Ohrm5uVR5Xl4ezM3NZe66UYZE7z1hLBw6dsKXXy8FUHVTZtAAN0ycNAUzZs3mODrlRnWrWMpavw1N9HN+v8nquE1jHBp2IQWQ+aPXtTLUsmXLUFRUVK8gqvvi31ZUVARtbe16nZPPKsrLcfvWTcyYNUdSpqamhl69XJCWeo3DyJQf1a1iNeX6VebZK+U2TfHkyZPRs2dPfP/996zfUz0ESSAQICQkBLq6upJ9YrEYSUlJcHR0lFeIvJFfkA+xWFzjZ66JiQkyM+9zFJVqoLpVrKZcv0qc5+WX6BMTE2VufV+7VtUCYBgG169fh5aWlmSflpYWunTpgqCgoHeeo7an0Bh19sObCCGEjSa1wtTo0aOlXjMMg+zsbFy9elXmB6aqR9tMmzYNUVFR9RovHxERgbCwMKmyr0JC8fXSZTKfq7EYGxlDXV0deXl5UuV5eXkwNTXlKCrVQHWrWE25fpV5zViZp0B4+9HeZs2aoW/fvjhy5AhCQ0PrFcSWLVvq/VBUcHAwXrx4IbUtWhxcr3M1Fk0tLdjZOyDpUqKkrLKyEklJiejcpSuHkSk/qlvFasr1qyZgt/GRTC16sViMadOmoVOnTnKdRrN///7v3P+uIZu1PYWmDKNupvhMQ8iXi+Hg0BEdO3XGb7ExKC0txchRo9//ZvJOVLeK1VTrl69JnA2ZEn31BGS3b9+Wa6Lv0qWL1Ou3h2yqosFDPJH//Dl+/GE9cnOfwfZDO/y46WeYqPjP38ZAdatYTbV+lbmPXuZx9N27d8eqVaswYMAARcUkUT1kU5aRPIBytOgJIY2roePovzic/v6DAKweatuwCymAzH301ROQHTp0CNnZ2SgsLJTa5Gny5Mn49ddf5XpOQgipD0UtJdgYWH/HhYeHY+HChY06AVl9hmwSQogi1GuBbZ5gnejDwsIwd+5chUxAJs8hm4QQogg8bayzwjrRV3flu7m5yT0IkUgk9VpNTQ22trYIDw/HoEGD5H49QgiRFdv56PlIptsTirrrvGXLFoWclxBC5EWJ87xsib5Dhw7vTfbPnz+vVyAFBQX4/fffce/ePSxatAjNmjVDcnIymjdvjpYtW9brnIQQIi98vdHKhkyJPiwsrEY3izykpaVhwIABMDIywoMHDzBr1iw0a9YM+/btQ1ZWFrZt2yb3axJCiCyUOM/LlugnTJhQY854eQgMDMS0adOwevVqGBgYSMo9PT0xadIkuV+PEEJkpcxz3bBO9Ip8KuzKlSvYtGlTjfKWLVsiJydHYdclhBC2mkQfvYwP0MpEKBTW+rDVnTt3YGZmprDrEkIIW8qc6Fk/A1BZWamQbhug6uGr8PBwVFRUAKj69ZCVlYXFixfjk08+Ucg1CSFEFupqAlYbH/HiYa81a9agqKgI5ubmKC0thZubG9q1awd9fX2sWLGC6/AIIQQCAbuNj+S2wlRDiEQinDhxAhcuXEBqaiqKiorg5OQEd3d3rkMjhBAATWh4pSLFx8cjPj4eT58+RWVlJf7++2/s2LEDAGhiM0II53jaK8MKLxJ9WFgYwsPD0b17d1haWir1vM+EENXUJIZXKlJ0dDS2bt2KKVOmcB0KIYTUSonzPD8SfXl5OVxcXLgOgxBC6qTMXTe8GHUzc+ZMSX88IYTwUZNYeESRXr16hc2bN+PkyZPo3LkzNDU1pfZHRkZyFBkhhFRpjDHy3377LYKDgxEQEIB169bJ7by8SPRpaWlwdHQEANy4cUNqH92YJYTwgaJTUfVUMJ07d5b7uXmR6BWxahUhhMiTIvu5i4qK4O3tjZ9++gnLly+X+/l50UdPCCF8JxAIWG1lZWUoLCyU2srKyt55bj8/PwwdOlRhD4lSoieEEBbUBQJWW0REBEQikdQWERFR53l37dqF5OTkdx7TULzouiGEEL5j20UfHByMwMBAqTKhUFjrsY8ePUJAQABOnDgBbW3tBkZYNwGjyPmHOfLqNdcREEL4RruBzdodyf+wOm6S0weszxkXF4dRo0ZBXV1dUiYWiyEQCKCmpoaysjKpffVFLXpCCGFBESMABwwYgOvXr0uVTZs2DR9++CEWL14slyQPUKInhBBWFDHXjYGBATp27ChVpqenBxMTkxrlDUGJnhBCWFDmJ3oo0RNCCAuN9fDmmTNn5H5OSvSE8Ihxj8+5DkFllV77oUHvV+ax6JToCSGEBb5OWMYGJXpCCGFBifM8JXpCCGFDTYlvx1KiJ4QQFqhFTwghKo766AkhRMVR1w0hhKg4JW7QU6InhBA2KNETQoiKU8RcN42FNw97nT9/HpMnT4azszMeP34MAIiNjUVCQgLHkRFCCCBg+R8f8SLR7927Fx4eHtDR0cG1a9cky269ePECK1eu5Dg6Qgip6rphs/ERLxL98uXLER0djZ9++gmampqScldXVyQnJ3MYGSGEVFHmFj0v+ujT09PRp0+fGuUikQgFBQWNHxAhhLyF+ugbyMLCAnfv3q1RnpCQgDZt2nAQESGESKOumwaaNWsWAgICkJSUBIFAgH///Rfbt29HUFAQPv30U67DI4QQCFhufMSLrpslS5agsrISAwYMQElJCfr06QOhUIigoCDMmzeP6/AIIUSpp0AQMAzDcB1EtfLycty9exdFRUWwt7eHvr5+vc7z6rWcAyOkkdDCI4rT0IVHLt0rYHVcr7ZGDbqOIvCi6+a3335DSUkJtLS0YG9vj549e9Y7yRNCiCIo86gbXiT6BQsWwNzcHJMmTcKRI0cgFou5DokQQqTQzdgGys7Oxq5duyAQCDBu3DhYWlrCz88PFy9e5Do0QggBoNw3Y3mR6DU0NDBs2DBs374dT58+xdq1a/HgwQP069cPbdu25To8QgiBQCBgtfERL0bdvElXVxceHh7Iz8/Hw4cPcfv2ba5DIoQQ3nbLsMGLFj0AlJSUYPv27fD09ETLli2xbt06jBo1Cjdv3uQ6NEIIUequG1606CdMmIBDhw5BV1cX48aNQ0hICJydnbkOixBC/oevWZwFXiR6dXV17NmzBx4eHlBXV+c6HEIIqUGZH5jiRddNdZcNJXlCCF8pousmIiICPXr0gIGBAczNzTFy5Eikp6fLM2wAHLbo169fj9mzZ0NbWxvr169/57H+/v6NFBUhhNRBAQ36s2fPws/PDz169MDr16/x5ZdfYtCgQbh16xb09PTkdh3OpkCwsbHB1atXYWJiAhsbmzqPEwgEuH//vkznVpYpEHbt2I6YLb8gN/cZOth+iCVfhqBT585ch6USlLVu+TYFgqtTWyyY6g4n+9awNBNh3ILN+ONMmmS/V/8umDmmN7ratYaJkR4+Gh+BtDuPOYy4bg2dAiHtURGr4zq3qv9T/c+ePYO5uTnOnj1b69Tt9cVZ101mZiZMTEwkf65rkzXJK4ujfx7B96sjMOczP+z6737Y2n6IT+fMQF5eHtehKT2qW/nR0xHi+p3HmB+xu9b9ujpauJhyD1+vj2vcwDigJmC3NcSLFy8AAM2aNZNDxP/Diz768PBwlJSU1CgvLS1FeHg4BxEpXmzMFoweMw4jR32Ctu3a4evQMGhrayNu316uQ1N6VLfyc/zCLYT9eAgHT6fVun/n4SuI2HwUpy7Jv1+Zd1h20peVlaGwsFBqq14e9V0qKysxf/58uLq6omPHjnINnReJPiwsDEVFNX8WlZSUICwsjIOIFKuivBy3b91EL2cXSZmamhp69XJBWuo1DiNTflS3RFHYTmoWEREBkUgktUVERLz3/H5+frhx4wZ27dol99h5MbySYZhaHx1OTU2V+08YPsgvyIdYLJZ0XVUzMTFBZqZqdlU1FqpboihsR1cGBwcjMDBQqkwoFL7zPZ9//jkOHTqEc+fO4YMPPqhviHXiNNEbGxtL5ofo0KGDVLIXi8UoKirC3Llz33mOsrKyGj+LGHXheyuWEEJkwTbRC4Xs8w/DMJg3bx7279+PM2fOvHNgSkNwmujXrVsHhmEwffp0hIWFQSQSSfZpaWnB2tr6vU/IRkRE1Oje+SokFF8vXaaIkOXC2MgY6urqNW4O5uXlwdTUlKOoVAPVLVEURcw17+fnhx07duDAgQMwMDBATk4OAEAkEkFHR0du1+E00fv4+ACoGmrp4uICTU1Nmc9R288kRp3frXlNLS3Y2Tsg6VIi+g9wB1B1IyYpKRETJk7mODrlRnVLFEURD8Zu3LgRANC3b1+p8i1btsDX11du1+Es0RcWFsLQ0BAA0LVrV5SWlqK0tLTWY6uPq01tP5OUYRz9FJ9pCPlyMRwcOqJjp874LTYGpaWlGDlqNNehKT2qW/nR09FC21ZmktfWLU3QuUNL5BeW4FFOPowNddHKwhiW5lW/xjtYNwcAPMkrxJO8l5zErCiKmAChsR5j4izRGxsbIzs7G+bm5jAyMqr1Zmz1TVpVXHFq8BBP5D9/jh9/WI/c3Gew/dAOP276GSbUvdBgVLfy42RvheM/B0herw76BAAQe/ASZof+hqFunfBT+BTJ/thV0wEAy6OPYMWmI40brILxda55Njh7Mvbs2bNwdXWFhoYGzp49+85j3dzcZDq3MrToCakN356MVSUNfTL27tPaexze1s5cfn3r8sJZi/7N5C1rIieEkMamvO15njwwdfToUSQkJEhe/+c//4GjoyMmTZqE/Px8DiMjhJD/p8Qrj/Ai0S9atAiFhYUAgOvXryMwMBCenp7IzMysMaKGEEK4oCYQsNr4iBdPxmZmZsLe3h4AsHfvXgwfPhwrV65EcnIyPD09OY6OEEJ421hnhRctei0tLcmkZidPnsSgQYMAVM3gVt3SJ4QQTilx1w0vWvS9e/dGYGAgXF1dcfnyZezeXTUl6p07dxQy7wMhhMhKEU/GNhZetOh/+OEHaGho4Pfff8fGjRvRsmVLAMCff/6JwYMHcxwdIYQ0znz0isLZOHpFonH0RFnROHrFaeg4+n/y3z+nPAB8YMy/KVh40XUDVM1WGRcXh9u3bwMAHBwcMGLECFownBDCEzxtrrPAi0R/9+5deHp64vHjx7C1tQVQNStlq1atcPjwYbRt25bjCAkhTR1PR06ywos+en9/f7Rt2xaPHj1CcnIykpOTkZWVBRsbG/j7+3MdHiGEKHUfPS9a9GfPnsWlS5ekVpMyMTHBt99+C1dXVw4jI4SQKso86oYXiV4oFOLly5pTmhYVFUFLS4uDiAgh5C3Km+f50XUzbNgwzJ49G0lJSWAYBgzD4NKlS5g7dy5GjBjBdXiEEKLMz0vxI9GvX78ebdu2hbOzM7S1taGtrQ0XFxe0a9cOUVFRXIdHCCE0101DGRkZ4cCBA7h79y5u3boFALC3t0e7du04jowQQv4fP3M4K7xI9ADwyy+/YO3atcjIyAAAtG/fHvPnz8fMmTM5jowQQpQ6z/Mj0S9duhSRkZGYN28enJ2dAQCJiYlYsGABsrKyEB4eznGEhJCmjqe9MqzwYgoEMzMzrF+/HhMnTpQq37lzJ+bNm4fc3FyZzkdTIBBlRVMgKE5Dp0DIL2G3drWxLv+e5ufFzdiKigp07969Rnm3bt3w+jVlbUIIaQheJPopU6Zg48aNNco3b94Mb29vDiIihBBpAgG7jY940UcPVN2MPX78OHr16gUASEpKQlZWFqZOnSq1nGBkZCRXIRJCmjB6MraBbty4AScnJwDAvXv3AACmpqYwNTXFjRs3JMcJ+Pp1SQhReXydx4YNXiT606dPcx0CIYS8mxInel700RNCCN8JWP5XH//5z39gbW0NbW1tfPTRR7h8+bJcY6dETwghLCjqZuzu3bsRGBiI0NBQJCcno0uXLvDw8MDTp0/lFjslekIIYUFRiT4yMhKzZs3CtGnTYG9vj+joaOjq6uLXX3+VW+yU6AkhhAVFdN2Ul5fjr7/+gru7u6RMTU0N7u7uSExMlFvsvLgZSwghfMe2tV5WVoayMumFxIVCIYTCmouG5+bmQiwWo3nz5lLlzZs3x99//13vWN+mkoleW4k+VVlZGSIiIhAcHFzrPwRSf8pYtw19TL+xKGPdNhTbvLJseQTCwsKkykJDQ7Fs2TL5B8USL+a6acoKCwshEonw4sULGBoach2OSqG6VRyq27rJ0qIvLy+Hrq4ufv/9d4wcOVJS7uPjg4KCAhw4cEAuMVEfPSGEyJFQKIShoaHUVtevHi0tLXTr1g3x8fGSssrKSsTHx0tm8pUHJerkIIQQ1RMYGAgfHx90794dPXv2xLp161BcXIxp06bJ7RqU6AkhhEPjx4/Hs2fPsHTpUuTk5MDR0RFHjx6tcYO2ISjRc0woFCI0NLTJ3NBqTFS3ikN1K1+ff/45Pv9ccWsR0M1YQghRcXQzlhBCVBwlekIIUXGU6JXIsmXL4OjoyHUYTZ61tTXWrVvHdRicOHPmDAQCAQoKCt55XFOuIz6iRM9TAoEAcXFxUmVBQUFS420JO3379sX8+fO5DkMluLi4IDs7GyKRCACwdetWGBkZ1TjuypUrmD17diNHR+pCo26UiL6+PvT19bkOQyUxDAOxWAwNDfpf4l20tLRgYWHx3uPMzMwaIRrCFrXo39K3b1/4+/vjiy++QLNmzWBhYSE1R0VBQQFmzpwJMzMzGBoaon///khNTZU6x/Lly2Fubg4DAwPMnDkTS5YskepyuXLlCgYOHAhTU1OIRCK4ubkhOTlZst/a2hoAMGrUKAgEAsnrN7tujh8/Dm1t7Ro/oQMCAtC/f3/J64SEBHz88cfQ0dFBq1at4O/vj+Li4gbXk7w0tL59fX2lHh0HgPnz56Nv376S/WfPnkVUVBQEAgEEAgEePHgg6YL4888/0a1bNwiFQiQkJODevXvw8vJC8+bNoa+vjx49euDkyZONUBPy07dvX8lwPZFIBFNTU4SEhKB6gF1+fj6mTp0KY2Nj6OrqYsiQIcjIyJC8/+HDhxg+fDiMjY2hp6cHBwcHHDlyBIB0182ZM2cwbdo0vHjxQlK31X93b3bdTJo0CePHj5eKsaKiAqampti2bRuAqqdBIyIiYGNjAx0dHXTp0gW///67gmuq6aBEX4uYmBjo6ekhKSkJq1evRnh4OE6cOAEAGDt2LJ4+fYo///wTf/31F5ycnDBgwAA8f/4cALB9+3asWLECq1atwl9//YXWrVtj48aNUud/+fIlfHx8kJCQgEuXLqF9+/bw9PTEy5cvAVR9EQDAli1bkJ2dLXn9pgEDBsDIyAh79+6VlInFYuzevRve3t4AqtbfHTx4MD755BOkpaVh9+7dSEhIUOh43fpoSH2/T1RUFJydnTFr1ixkZ2cjOzsbrVq1kuxfsmQJvv32W9y+fRudO3dGUVERPD09ER8fj2vXrmHw4MEYPnw4srKyFPLZFSUmJgYaGhq4fPkyoqKiEBkZiZ9//hlA1Zff1atXcfDgQSQmJoJhGHh6eqKiogIA4Ofnh7KyMpw7dw7Xr1/HqlWrav0l6eLignXr1sHQ0FBSt0FBQTWO8/b2xh9//IGioiJJ2bFjx1BSUoJRo0YBACIiIrBt2zZER0fj5s2bWLBgASZPnoyzZ88qonqaHoZIcXNzY3r37i1V1qNHD2bx4sXM+fPnGUNDQ+bVq1dS+9u2bcts2rSJYRiG+eijjxg/Pz+p/a6urkyXLl3qvKZYLGYMDAyYP/74Q1IGgNm/f7/UcaGhoVLnCQgIYPr37y95fezYMUYoFDL5+fkMwzDMjBkzmNmzZ0ud4/z584yamhpTWlpaZzyNqaH17ePjw3h5eUntDwgIYNzc3KSuERAQIHXM6dOnGQBMXFzce2N0cHBgNmzYIHltZWXFrF279v0fjiNubm6MnZ0dU1lZKSlbvHgxY2dnx9y5c4cBwFy4cEGyLzc3l9HR0WH27NnDMAzDdOrUiVm2bFmt566ut+p/Y1u2bGFEIlGN496so4qKCsbU1JTZtm2bZP/EiROZ8ePHMwzDMK9evWJ0dXWZixcvSp1jxowZzMSJE2X+/KQmatHXonPnzlKvLS0t8fTpU6SmpqKoqAgmJiaS/nJ9fX1kZmbi3r17AID09HT07NlT6v1vv37y5AlmzZqF9u3bQyQSwdDQEEVFRTK3Gr29vXHmzBn8+++/AKp+TQwdOlRycyw1NRVbt26VitXDwwOVlZXIzMyU6VqK1JD6bqju3btLvS4qKkJQUBDs7OxgZGQEfX193L59W+la9L169YLgjQnUnZ2dkZGRgVu3bkFDQwMfffSRZJ+JiQlsbW1x+/ZtAIC/vz+WL18OV1dXhIaGIi0trUGxaGhoYNy4cdi+fTsAoLi4GAcOHJD88rx79y5KSkowcOBAqb/nbdu2ye3vuamjO0+10NTUlHotEAhQWVmJoqIiWFpa4syZMzXeU9vIg7r4+PggLy8PUVFRsLKyglAohLOzM8rLy2WKs0ePHmjbti127dqFTz/9FPv378fWrVsl+4uKijBnzhz4+/vXeG/r1q1lupYiNaS+1dTUJH3P1aq7INjQ09OTeh0UFIQTJ07g+++/R7t27aCjo4MxY8bI/HejzGbOnAkPDw8cPnwYx48fR0REBNasWYN58+bV+5ze3t5wc3PD06dPceLECejo6GDw4MEAIOnSOXz4MFq2bCn1PppiQT4o0cvAyckJOTk50NDQkNwgfZutrS2uXLmCqVOnSsre7mO/cOECfvzxR3h6egIAHj16hNzcXKljNDU1IRaL3xuTt7c3tm/fjg8++ABqamoYOnSoVLy3bt1Cu3bt2H5EXmFT32ZmZrhx44ZUWUpKitSXh5aWFqu6BKr+bnx9fSV9x0VFRXjw4EG94udSUlKS1Ovqe0H29vZ4/fo1kpKS4OLiAgDIy8tDeno67O3tJce3atUKc+fOxdy5cxEcHIyffvqp1kTPtm5dXFzQqlUr7N69G3/++SfGjh0r+Tuyt7eHUChEVlYW3NzcGvKxSR2o60YG7u7ucHZ2xsiRI3H8+HE8ePAAFy9exFdffYWrV68CAObNm4dffvkFMTExyMjIwPLly5GWlib1M7p9+/aIjY3F7du3kZSUBG9vb+jo6Ehdy9raGvHx8cjJyUF+fn6dMXl7eyM5ORkrVqzAmDFjpFpAixcvxsWLF/H5558jJSUFGRkZOHDgAO9uxtaFTX33798fV69exbZt25CRkYHQ0NAaid/a2hpJSUl48OABcnNzUVlZWec127dvj3379iElJQWpqamYNGnSO4/nq6ysLAQGBiI9PR07d+7Ehg0bEBAQgPbt28PLywuzZs1CQkICUlNTMXnyZLRs2RJeXl4AqkYtHTt2DJmZmUhOTsbp06dhZ2dX63Wsra1RVFSE+Ph45ObmoqSkpM6YJk2ahOjoaJw4cULSbQMABgYGCAoKwoIFCxATE4N79+4hOTkZGzZsQExMjHwrpomiRC8DgUCAI0eOoE+fPpg2bRo6dOiACRMm4OHDh5IpRb29vREcHIygoCA4OTkhMzMTvr6+0NbWlpznl19+QX5+PpycnDBlyhT4+/vD3Nxc6lpr1qzBiRMn0KpVK3Tt2rXOmNq1a4eePXsiLS1N6n8eoKrv++zZs7hz5w4+/vhjdO3aFUuXLkWLFi3kWCuKw6a+PTw8EBISgi+++AI9evTAy5cvpX5NAVXdMerq6rC3t4eZmdk7+9sjIyNhbGwMFxcXDB8+HB4eHnByclLo51SEqVOnorS0FD179oSfnx8CAgIkDzBt2bIF3bp1w7Bhw+Ds7AyGYXDkyBFJC1ssFsPPzw92dnYYPHgwOnTogB9//LHW67i4uGDu3LkYP348zMzMsHr16jpj8vb2xq1bt9CyZUu4urpK7fvmm28QEhKCiIgIyXUPHz4MGxsbOdVI00azVzaCgQMHwsLCArGxsVyHQpqAvn37wtHRkaYgIBLURy9nJSUliI6OhoeHB9TV1bFz506cPHlSMi6cEEIaGyV6OavublixYgVevXoFW1tb7N27F+7u7lyHRghpoqjrhhBCVBzdjCWEEBVHiZ4QQlQcJXpCCFFxlOgJIUTFUaInhBAVR4meqIy3FyHhaglBtuuqEtJYKNEThfP19ZWsQKSlpYV27dohPDwcr1+/Vuh19+3bh2+++YbVsZSciSqjB6ZIoxg8eDC2bNmCsrIyHDlyBH5+ftDU1ERwcLDUceXl5dDS0pLLNZs1ayaX8xCi7KhFTxqFUCiEhYUFrKys8Omnn8Ld3R0HDx6UdLesWLECLVq0gK2tLYCqqZvHjRsHIyMjNGvWDF5eXlLTBYvFYgQGBsLIyAgmJib44osvasxL/3bXTVlZGRYvXoxWrVpBKBSiXbt2+OWXX/DgwQP069cPAGBsbAyBQABfX18A7NYyPXLkCDp06AAdHR3069dPKac1JqqNEj3hhI6OjmQxj/j4eKSnp+PEiRM4dOgQKioq4OHhAQMDA5w/fx4XLlyAvr4+Bg8eLHnPmjVrsHXrVvz6669ISEjA8+fPsX///ndec+rUqdi5cyfWr1+P27dvY9OmTdDX10erVq0ka++mp6cjOzsbUVFRAN6/lumjR48wevRoDB8+HCkpKZLF4AnhFQ6XMSRNxJvrulZWVjInTpxghEIhExQUxPj4+DDNmzdnysrKJMfHxsYytra2UmuelpWVMTo6OsyxY8cYhmEYS0tLZvXq1ZL9FRUVzAcffCC1fuyba8Wmp6czAJgTJ07UGuPba6EyDLu1TIODgxl7e3up/YsXL65xLkK4RH30pFEcOnQI+vr6qKioQGVlJSZNmoRly5bBz88PnTp1kuqXT01Nxd27d2FgYCB1jlevXuHevXt48eIFsrOzpdY91dDQQPfu3Wt031RLSUmBurq6TCsYvbmW6ZvKy8slawTcvn1bKg6gan1WQviEEj1pFP369cPGjRuhpaWFFi1aQEPjf//03l63taioCN26dZMsJv0mMzOzel3/7RW82KC1TImqoERPGoWenh7rtWudnJywe/dumJubw9DQsNZjLC0tkZSUhD59+gAAXr9+jb/++qvO1aA6deqEyspKnD17ttYpo6t/Uby5/imbtUzt7Oxw8OBBqbJLly69/0MS0ojoZizhHW9vb5iamsLLywvnz59HZmYmzpw5A39/f/zzzz8AgICAAHz77beIi4vD33//jc8+++ydY+Ctra3h4+OD6dOnIy4uTnLOPXv2AACsrKwgEAhw6NAhPHv2DEVFRazWMp07dy4yMjKwaNEipKenY8eOHdi6dauiq4gQmVCiJ7yjq6uLc+fOoXXr1hg9ejTs7OwwY8YMvHr1StLCX7hwIaZMmQIfHx84OzvDwMAAo0aNeud5N27ciDFjxuCzzz7Dhx9+iFmzZqG4uBgA0LJlS4SFhWHJkiVo3ry5ZAH1961l2rp1a+zduxdxcXHo0qULoqOjsXLlSgXWDiGyo4VHCCFExVGLnhBCVBwlekIIUXGU6AkhRMVRoieEEBVHiZ4QQlQcJXpCCFFxlOgJIUTFUaInhBAVR4meEEJUHCV6QghRcZToCSFExVGiJ4QQFfd/vTnB5v3+bxQAAAAASUVORK5CYII=\n"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"#Cell10Sample Predictions,Misclassifications\nimport random\n\nval_texts = val_df.reset_index(drop=True)[\"Text\"].tolist()\nval_true_names = [id2label[i] for i in y_true]\nval_pred_names = [id2label[i] for i in y_pred]\n\nn_samples = min(15, len(val_texts))\nidxs = random.sample(range(len(val_texts)), k=n_samples)\n\nprint(f\"Sample predictions ({n_samples}):\\n\")\nfor i in idxs:\n    txt = val_texts[i]\n    print(f\"- True: {val_true_names[i]} | Pred: {val_pred_names[i]}\")\n    print(f\"  Text: {txt[:300]}{'...' if len(txt)>300 else ''}\\n\")\n\nmis = [i for i in range(len(y_true)) if y_true[i] != y_pred[i]]\nprint(f\"\\nTotal misclassified: {len(mis)}\")\nfor i in mis[:3]:\n    txt = val_texts[i]\n    print(f\"[MISCLASSIFIED] True={val_true_names[i]} Pred={val_pred_names[i]}\")\n    print(f\"Text: {txt[:400]}{'...' if len(txt)>400 else ''}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T22:13:33.528738Z","iopub.execute_input":"2025-11-10T22:13:33.529391Z","iopub.status.idle":"2025-11-10T22:13:33.537418Z","shell.execute_reply.started":"2025-11-10T22:13:33.529365Z","shell.execute_reply":"2025-11-10T22:13:33.536463Z"}},"outputs":[{"name":"stdout","text":"Sample predictions (15):\n\n- True: positive | Pred: positive\n  Text: I can't stop listening to this song. It's my new favorite!\n\n- True: positive | Pred: positive\n  Text: I'm captivated by this band's unique sound. They're a breath of fresh air!\n\n- True: positive | Pred: positive\n  Text: This book made me feel inspired. Highly recommended!\n\n- True: negative | Pred: negative\n  Text: The product I received was damaged. Unacceptable.\n\n- True: negative | Pred: negative\n  Text: I had a terrible experience with their delivery service. Late and unprofessional.\n\n- True: positive | Pred: positive\n  Text: The roller coaster ride was exhilarating! Pure adrenaline rush!\n\n- True: positive | Pred: positive\n  Text: The hotel stay was absolutely amazing! Luxury at its finest.\n\n- True: positive | Pred: positive\n  Text: This movie is amazing!\n\n- True: negative | Pred: negative\n  Text: The customer service at this hotel was terrible. Avoid at all costs.\n\n- True: negative | Pred: negative\n  Text: The quality of this product is subpar.\n\n- True: positive | Pred: positive\n  Text: This book made me feel inspired. Highly recommended!\n\n- True: negative | Pred: negative\n  Text: The product I ordered arrived damaged. Very disappointed with the packaging.\n\n- True: positive | Pred: positive\n  Text: This restaurant has the most delicious food. I can't wait to go back!\n\n- True: negative | Pred: negative\n  Text: The product I purchased broke within a week. Poor quality.\n\n- True: negative | Pred: negative\n  Text: The website layout is cluttered and confusing. Difficult to find information.\n\n\nTotal misclassified: 0\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"#Cell 11Save Best Model & Tokenizer\nsave_dir = os.path.join(OUTPUT_DIR, \"best_model\")\ntrainer.save_model(save_dir)        # saves model + config\ntokenizer.save_pretrained(save_dir) # saves tokenizer files\nprint(\"Saved model and tokenizer to:\", save_dir)\n\n# List saved files\n!ls -lh {save_dir}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T22:13:47.539471Z","iopub.execute_input":"2025-11-10T22:13:47.540067Z","iopub.status.idle":"2025-11-10T22:13:48.579803Z","shell.execute_reply.started":"2025-11-10T22:13:47.540037Z","shell.execute_reply":"2025-11-10T22:13:48.578761Z"}},"outputs":[{"name":"stdout","text":"Saved model and tokenizer to: /kaggle/working/sentiment_outputs/best_model\ntotal 419M\n-rw-r--r-- 1 root root  839 Nov 10 22:13 config.json\n-rw-r--r-- 1 root root 418M Nov 10 22:13 model.safetensors\n-rw-r--r-- 1 root root  125 Nov 10 22:13 special_tokens_map.json\n-rw-r--r-- 1 root root 1.2K Nov 10 22:13 tokenizer_config.json\n-rw-r--r-- 1 root root 695K Nov 10 22:13 tokenizer.json\n-rw-r--r-- 1 root root 5.4K Nov 10 22:13 training_args.bin\n-rw-r--r-- 1 root root 227K Nov 10 22:13 vocab.txt\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"#cell12Inference Utility (Predict on New Texts)\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\ndef predict_texts(texts, model_dir, max_length=MAX_LENGTH):\n    tok = AutoTokenizer.from_pretrained(model_dir)\n    mdl = AutoModelForSequenceClassification.from_pretrained(model_dir)\n    mdl.eval()\n    enc = tok(texts, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\")\n    with torch.no_grad():\n        out = mdl(**enc)\n    probs = out.logits.softmax(-1).numpy()\n    id2label_local = mdl.config.id2label\n    results = []\n    for i, t in enumerate(texts):\n        pred_id = int(probs[i].argmax())\n        results.append({\n            \"text\": t,\n            \"prediction\": id2label_local[pred_id],\n            \"probs\": {id2label_local[j]: float(probs[i][j]) for j in range(probs.shape[1])}\n        })\n    return results\n\nsample_inputs = [\n    \"The product quality is outstanding and I love it!\",\n    \"It was okay, not great but not terrible.\",\n    \"Really disappointed with the service, would not recommend.\",\n]\n\ninference_results = predict_texts(sample_inputs, save_dir)\nfor r in inference_results:\n    print(r)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T22:13:59.456055Z","iopub.execute_input":"2025-11-10T22:13:59.456799Z","iopub.status.idle":"2025-11-10T22:13:59.779045Z","shell.execute_reply.started":"2025-11-10T22:13:59.456771Z","shell.execute_reply":"2025-11-10T22:13:59.778306Z"}},"outputs":[{"name":"stdout","text":"{'text': 'The product quality is outstanding and I love it!', 'prediction': 'positive', 'probs': {'negative': 0.19026805460453033, 'neutral': 0.30545714497566223, 'positive': 0.5042747855186462}}\n{'text': 'It was okay, not great but not terrible.', 'prediction': 'negative', 'probs': {'negative': 0.42710641026496887, 'neutral': 0.25546687841415405, 'positive': 0.31742674112319946}}\n{'text': 'Really disappointed with the service, would not recommend.', 'prediction': 'negative', 'probs': {'negative': 0.4852433204650879, 'neutral': 0.2478560209274292, 'positive': 0.2669007182121277}}\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"#cell13Export Metrics & Samples for Report\nimport json\n# Store evaluation metrics\nwith open(os.path.join(OUTPUT_DIR, \"eval_metrics.json\"), \"w\") as f:\n    json.dump(eval_result, f, indent=2)\n\n# Store a subset of validation predictions\nsample_records = []\nlimit = min(200, len(val_texts))\nfor i in range(limit):\n    sample_records.append({\n        \"text\": val_texts[i],\n        \"true\": val_true_names[i],\n        \"pred\": val_pred_names[i]\n    })\n\nwith open(os.path.join(OUTPUT_DIR, \"sample_predictions.json\"), \"w\") as f:\n    json.dump(sample_records, f, indent=2)\n\nprint(\"Saved eval_metrics.json and sample_predictions.json in\", OUTPUT_DIR)\n!ls -lh {OUTPUT_DIR}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T22:14:07.353547Z","iopub.execute_input":"2025-11-10T22:14:07.353841Z","iopub.status.idle":"2025-11-10T22:14:07.543426Z","shell.execute_reply.started":"2025-11-10T22:14:07.353822Z","shell.execute_reply":"2025-11-10T22:14:07.542349Z"}},"outputs":[{"name":"stdout","text":"Saved eval_metrics.json and sample_predictions.json in /kaggle/working/sentiment_outputs\ntotal 16K\ndrwxr-xr-x 2 root root 4.0K Nov 10 22:13 best_model\ndrwxr-xr-x 4 root root 4.0K Nov 10 22:13 checkpoints\n-rw-r--r-- 1 root root  227 Nov 10 22:14 eval_metrics.json\n-rw-r--r-- 1 root root 2.6K Nov 10 22:14 sample_predictions.json\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"!pip -q install --upgrade gradio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T22:15:39.309014Z","iopub.execute_input":"2025-11-10T22:15:39.309470Z","iopub.status.idle":"2025-11-10T22:15:43.408845Z","shell.execute_reply.started":"2025-11-10T22:15:39.309439Z","shell.execute_reply":"2025-11-10T22:15:43.407673Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Install Gradio (safe to re-run)\n!pip -q install --upgrade gradio\n\nimport os, torch, pandas as pd, gradio as gr\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\n# Silence tokenizer parallelism warning\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\n# Path to your saved model from Cell 11\nMODEL_DIR = \"/kaggle/working/sentiment_outputs/best_model\"\nMAX_LENGTH = 256\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load model + tokenizer\ntokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\nmodel = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR).to(device).eval()\n\n# Labels in order 0..num_labels-1\nnum_labels = model.config.num_labels\nid2label = model.config.id2label\nlabel_order = [id2label[i] for i in range(num_labels)]\n\ndef predict_single(text: str):\n    \"\"\"Predict sentiment for a single text. Returns (Label component dict, JSON).\"\"\"\n    if not isinstance(text, str) or not text.strip():\n        return {\"\": 0.0}, {\"error\": \"Empty input\", \"prediction\": None, \"probs\": {}}\n\n    enc = tokenizer([text], padding=True, truncation=True, max_length=MAX_LENGTH, return_tensors=\"pt\").to(device)\n    with torch.no_grad():\n        logits = model(**enc).logits\n        probs = torch.softmax(logits, dim=-1)[0].detach().cpu().numpy()\n\n    conf_map = {label_order[i]: float(probs[i]) for i in range(num_labels)}\n    result_json = {\n        \"text\": text,\n        \"prediction\": max(conf_map, key=conf_map.get),\n        \"probs\": conf_map\n    }\n    return conf_map, result_json\n\ndef predict_csv(file_obj):\n    \"\"\"\n    Batch predict for a CSV. Expects a 'Text' column (case-insensitive handled).\n    Returns a dataframe: Text, prediction, prob_<label>...\n    \"\"\"\n    if file_obj is None:\n        return pd.DataFrame([{\"error\": \"No file uploaded\"}])\n\n    df = pd.read_csv(file_obj.name)\n    df.columns = df.columns.str.strip()\n\n    # Normalize to 'Text' if a common alternative exists\n    if \"Text\" not in df.columns:\n        candidates = [c for c in df.columns if c.lower() in {\"text\", \"review\", \"feedback\", \"comment\", \"sentence\"}]\n        if candidates:\n            df = df.rename(columns={candidates[0]: \"Text\"})\n        else:\n            return pd.DataFrame([{\"error\": \"CSV must contain a 'Text' column.\"}])\n\n    texts = df[\"Text\"].astype(str).fillna(\"\").tolist()\n    if len(texts) == 0:\n        return pd.DataFrame([{\"error\": \"No rows found in 'Text' column.\"}])\n\n    # Batch tokenize for speed\n    enc = tokenizer(texts, padding=True, truncation=True, max_length=MAX_LENGTH, return_tensors=\"pt\").to(device)\n    with torch.no_grad():\n        logits = model(**enc).logits\n        probs = torch.softmax(logits, dim=-1).detach().cpu().numpy()\n\n    preds = probs.argmax(axis=1)\n    pred_labels = [id2label[int(i)] for i in preds]\n\n    out_df = pd.DataFrame({\"Text\": texts, \"prediction\": pred_labels})\n    for i, label in enumerate(label_order):\n        out_df[f\"prob_{label}\"] = probs[:, i]\n\n    return out_df\n\n# Build Gradio UI\ndemo = gr.Blocks(title=\"BERT Sentiment Classifier\")\nwith demo:\n    gr.Markdown(\"# BERT Sentiment Classifier\\nEnter text or upload a CSV with a 'Text' column.\")\n    with gr.Tabs():\n        with gr.Tab(\"Single Text\"):\n            inp = gr.Textbox(lines=4, label=\"Enter customer feedback\")\n            btn = gr.Button(\"Predict\")\n            out_label = gr.Label(num_top_classes=len(label_order), label=\"Prediction (confidence)\")\n            out_json = gr.JSON(label=\"Raw output\")\n            examples = gr.Examples(\n                examples=[\n                    \"I absolutely love this product! Exceeded my expectations.\",\n                    \"It was okay, nothing special.\",\n                    \"Very disappointed. The service was terrible.\"\n                ],\n                inputs=inp\n            )\n            btn.click(fn=predict_single, inputs=inp, outputs=[out_label, out_json])\n\n        with gr.Tab(\"Batch CSV\"):\n            file_in = gr.File(file_count=\"single\", file_types=[\".csv\"], label=\"Upload CSV with a 'Text' column\")\n            btn2 = gr.Button(\"Run batch prediction\")\n            out_df = gr.Dataframe(label=\"Results\", wrap=True)\n            btn2.click(fn=predict_csv, inputs=file_in, outputs=out_df)\n\n# IMPORTANT for Kaggle: use share=True (Internet must be ON). Click the public link printed below.\n# If you prefer inline and it works in your session, change inline=True and share=False.\ngr.close_all()  # ensure no previous server is running\ndemo.queue().launch(\n    share=True,              # creates a public gradio.live link\n    server_name=\"0.0.0.0\",\n    server_port=7860,\n    inline=False,            # rely on the public link instead of 127.0.0.1\n    show_error=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T22:22:55.734305Z","iopub.execute_input":"2025-11-10T22:22:55.734871Z","iopub.status.idle":"2025-11-10T22:23:01.561190Z","shell.execute_reply.started":"2025-11-10T22:22:55.734846Z","shell.execute_reply":"2025-11-10T22:23:01.560522Z"}},"outputs":[{"name":"stdout","text":"Closing server running on port: 7861\nClosing server running on port: 7860\n* Running on local URL:  http://0.0.0.0:7860\n* Running on public URL: https://a2bafb64859a8a10cb.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}